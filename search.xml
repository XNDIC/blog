<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PreFLMR运行记录</title>
      <link href="/2024/10/22/PreFLMR%E8%BF%90%E8%A1%8C%E8%AE%B0%E5%BD%95/"/>
      <url>/2024/10/22/PreFLMR%E8%BF%90%E8%A1%8C%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h1 id="PreFLMR运行记录"><a href="#PreFLMR运行记录" class="headerlink" title="PreFLMR运行记录"></a>PreFLMR运行记录</h1><h3 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h3><h4 id="1-创建虚拟环境"><a href="#1-创建虚拟环境" class="headerlink" title="1.创建虚拟环境"></a>1.创建虚拟环境</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n lmjFLMR python=3.10 -y</span><br></pre></td></tr></table></figure><p>虚拟环境安装失败，出现<code>An unexpected error has occurred. Conda has prepared the above report.</code>报错。</p><p>解决方法【成功】：<a href="https://www.jianshu.com/p/9e76e679d2f8">删除.condarc文件</a></p><h4 id="2-激活虚拟环境lmjFLMR"><a href="#2-激活虚拟环境lmjFLMR" class="headerlink" title="2.激活虚拟环境lmjFLMR"></a>2.激活虚拟环境lmjFLMR</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda activate lmjFLMR</span><br></pre></td></tr></table></figure><h4 id="3-安装-Pytorch"><a href="#3-安装-Pytorch" class="headerlink" title="3.安装 Pytorch"></a>3.安装 Pytorch</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span><br></pre></td></tr></table></figure><p>安装失败，出现<code>ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device</code>。</p><p><img src="/2024/10/22/PreFLMR%E8%BF%90%E8%A1%8C%E8%AE%B0%E5%BD%95/%E5%AE%89%E8%A3%85pytorch%E6%8A%A5%E9%94%99.png" alt="安装pytorch报错"></p><p>解决方法1【失败】：使用<code>--no-cache-dir</code>参数忽略缓存，减少存储空间的使用</p><p>解决方法2：<a href="https://blog.csdn.net/qq_43340256/article/details/131943325">删除虚拟环境，重新创建虚拟环境时使用–prefix参数，指定虚拟环境的位置</a></p><h4 id="4-安装-faiss"><a href="#4-安装-faiss" class="headerlink" title="4.安装 faiss"></a>4.安装 faiss</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install -c pytorch -c nvidia faiss-gpu=1.7.4 mkl=2021 blas=1.0=mkl</span><br></pre></td></tr></table></figure><p>Test if faiss generate error<br>测试 faiss 是否生成错误</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -c &quot;import faiss&quot;</span><br></pre></td></tr></table></figure><p>Install FLMR 安装 FLMR</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/LinWeizheDragon/FLMR.git</span><br><span class="line">cd FLMR</span><br><span class="line">pip install -e .</span><br></pre></td></tr></table></figure><p>Install ColBERT engine 安装 ColBERT 引擎</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd third_party/ColBERT</span><br><span class="line">pip install -e .</span><br></pre></td></tr></table></figure><p>Install other dependencies<br>安装其他依赖项</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install ujson gitpython easydict ninja datasets transformers</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 项目 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>conda虚拟环境</title>
      <link href="/2024/10/22/conda%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/"/>
      <url>/2024/10/22/conda%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="conda虚拟环境"><a href="#conda虚拟环境" class="headerlink" title="conda虚拟环境"></a>conda虚拟环境</h1><h3 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h3><p>conda create python&#x3D;3.10 -y –prefix &#x2F;mnt&#x2F;data&#x2F;lmj&#x2F;lmjFLMR </p><p>environment location: &#x2F;mnt&#x2F;data&#x2F;lmj&#x2F;lmjFLMR</p><hr><h3 id="创建一个名为myenv的虚拟环境，并指定其位置为-home-user-myenv"><a href="#创建一个名为myenv的虚拟环境，并指定其位置为-home-user-myenv" class="headerlink" title="创建一个名为myenv的虚拟环境，并指定其位置为&#x2F;home&#x2F;user&#x2F;myenv"></a>创建一个名为myenv的虚拟环境，并指定其位置为&#x2F;home&#x2F;user&#x2F;myenv</h3><p>conda create –prefix &#x2F;home&#x2F;user&#x2F;myenv</p><h3 id="激活该虚拟环境"><a href="#激活该虚拟环境" class="headerlink" title="激活该虚拟环境"></a>激活该虚拟环境</h3><p>conda activate &#x2F;home&#x2F;user&#x2F;myenv</p><h3 id="删除该虚拟环境"><a href="#删除该虚拟环境" class="headerlink" title="删除该虚拟环境"></a>删除该虚拟环境</h3><p>conda remove –prefix &#x2F;home&#x2F;user&#x2F;myenv –all</p><p>conda remove -n 虚拟环境名称 –all</p><h4 id="关闭conda环境"><a href="#关闭conda环境" class="headerlink" title="关闭conda环境"></a>关闭conda环境</h4><p>conda deactivate</p>]]></content>
      
      
      
        <tags>
            
            <tag> 环境配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3DGS</title>
      <link href="/2024/10/16/3DGS/"/>
      <url>/2024/10/16/3DGS/</url>
      
        <content type="html"><![CDATA[<h2 id="3D-Gaussian-Splatting-3DGS"><a href="#3D-Gaussian-Splatting-3DGS" class="headerlink" title="3D Gaussian Splatting(3DGS)"></a>3D Gaussian Splatting(3DGS)</h2><p>学习来源：</p><p>代码地址：</p><p>论文地址：3D Gaussian Splatting for Real-Time Radiance Field Rendering</p><p>基于Splatting和机器学习的三维重建方法</p><p>无深度学习，只有简单的机器学习＋大量的CG知识＋复杂的线性代数，是对GPU的高性能编程</p><h3 id="Splatting"><a href="#Splatting" class="headerlink" title="Splatting"></a>Splatting</h3><h4 id="基本理解"><a href="#基本理解" class="headerlink" title="基本理解"></a>基本理解</h4><p>定义：一种从3D物体渲染到2D平面的体渲染方法</p><p>NeRF中的体渲染是一种被动的方法(Ray-casting)，计算出每个像素点受到发光粒子的影响来生成图片（主角是像素）。Splatting是主动的，计算出每个发光粒子是如何影响像素点（主角是粒子）。</p><h4 id="为什么叫splatting"><a href="#为什么叫splatting" class="headerlink" title="为什么叫splatting"></a>为什么叫splatting</h4><p>Splat：拟声词，啪唧一声</p><p>想象输入是一些雪球，图片是一面砖墙；图片生成的过程就是向墙面扔雪球的过程，每扔一个雪球，墙面上就会留下扩散痕迹（足迹footprint），同时会有啪唧一声，由此得名。这个算法也可以叫抛雪球算法、足迹法，也会被翻译为喷溅。</p><p>所以splatting的核心：选择“雪球”；抛掷雪球：从3D投影到2D，得到足迹；加以合成，最后形成图像</p><h3 id="选择雪球：3D高斯椭球"><a href="#选择雪球：3D高斯椭球" class="headerlink" title="选择雪球：3D高斯椭球"></a>选择雪球：3D高斯椭球</h3><p>有很好的数学性质：</p><ul><li>仿射变换后高斯核仍然闭合</li><li>3D降维到2D后（沿着某一个轴积分），依然为高斯</li></ul><p>定义：椭球高斯$G(x)=\frac1{\sqrt{(2\pi)^k\mid\sum\mid}}e^{-\frac12(x-\mu)^T\sum^{-1}(x-\mu)}$，其中$\sum$表示协方差矩阵，==半正定==，$\mid\sum\mid$是其行列式</p><p><img src="/2024/10/16/3DGS/image-20241016202550441.png" alt="image-20241016202550441" style="zoom: 80%;"></p><h4 id="为什么是椭球"><a href="#为什么是椭球" class="headerlink" title="为什么是椭球"></a>为什么是椭球</h4><p>椭球：$\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1$，即$Ax^2+By^2+Cz^2+2Dxy+2Eyz+2Fyz=1$</p><h5 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h5><p>一维时形状由均值和方差决定，二维时由均值和协方差矩阵决定，高斯分布概率范围是[0,1]</p><p><img src="/2024/10/16/3DGS/image-20241016203623911.png" alt="image-20241016203623911" style="zoom:80%;"></p><p>协方差矩阵：是一个对称矩阵，决定高斯分布的形状；对角线上的元素是xyz轴的方差，反斜对角线上的值为协方差，表示两者的线性相关程度。<br>$\sum=\left[\begin{matrix}\sigma<em>x^2&amp;\sigma</em>{xy}&amp;\sigma<em>{xz}&amp;\ \sigma</em>{yx}&amp;\sigma<em>y^2&amp;\sigma</em>{yz}&amp;\ \sigma<em>{zx}&amp;\sigma</em>{zy}&amp;\sigma_z^2&amp; \end{matrix}\right]$</p><p>$G(x;\mu,\sum)=\frac1{\sqrt{(2\pi)^k\mid\sum\mid}}exp(-\frac12(x-\mu)^T\sum^{-1}(x-\mu))$<br>当$(x-\mu)^T\sum^{-1}(x-\mu)=constant$时，$G(x;\mu,\sum)=constant$<br>一维时$\frac{(x-\mu)^2}{\sigma^2}=constant$<br>二维时$\frac{(x-\mu<em>1)^2}{\sigma_1^2}+\frac{(y-\mu_2)^2}{\sigma_2^2}-\frac{2\sigma</em>{xy}(x-\mu<em>1)(y-\mu_2)}{\sigma_1\sigma_2}=constant$（椭圆）<br>三维时$constant=(x-\mu)^T\sum^{-1}(x-\mu)=\frac{(x-\mu_1)^2}{\sigma_1^2}+\frac{(y-\mu_2)^2}{\sigma_2^2}+\frac{(z-\mu_3)^2}{\sigma_3^2}-\frac{2\sigma</em>{xy}(x-\mu<em>1)(y-\mu_2)}{\sigma_1\sigma_2}-\frac{2\sigma</em>{xz}(x-\mu<em>1)(y-\mu_3)}{\sigma_1\sigma_3}-\frac{2\sigma</em>{yz}(x-\mu_2)(y-\mu_3)}{\sigma_2\sigma_3}$【注：这个等式最上面的x和第二行的x不是一个概念，上面的x是个3x1的(x,y,z)】，即$Ax^2+By^2+Cz^2+2Dxy+2Eyz+2Fyz=1$，是椭球面</p><p>三维下，$G(x;\mu,\sum)=[0,1]$，每一个常数都是一个椭球壳（g为常数的时候是一个面，而高斯的g是从0-1的连续值），就是椭球壳的分布，所以是大椭球壳套小椭球壳，即实心的椭球</p><h5 id="各向同性和各向异性"><a href="#各向同性和各向异性" class="headerlink" title="各向同性和各向异性"></a>各向同性和各向异性</h5><p>各向同性(Isotropic)：在所有方向都具有相同的扩散程度(梯度)，eg: 球。在3d高斯分布下，协方差矩阵是对角矩阵：$\sum=\left[\begin{matrix}\sigma^2&amp;0&amp;0&amp;\ 0&amp;\sigma^2&amp;0&amp;\ 0&amp;0&amp;\sigma^2&amp; \end{matrix}\right]$，xy、yz、xz之间都不相关</p><p>各向异性(Anisotropic)：在不同方向具有不同的扩散程度(梯度)，eg: 椭球。在3d高斯分布下，协方差矩阵是对角矩阵：$\sum=\left[\begin{matrix}\sigma<em>x^2&amp;\sigma</em>{xy}&amp;\sigma<em>{xz}&amp;\ \sigma</em>{yx}&amp;\sigma<em>y^2&amp;\sigma</em>{yz}&amp;\ \sigma<em>{zx}&amp;\sigma</em>{zy}&amp;\sigma_z^2&amp; \end{matrix}\right]$</p><h4 id="协方差矩阵如何控制椭球形状"><a href="#协方差矩阵如何控制椭球形状" class="headerlink" title="协方差矩阵如何控制椭球形状"></a>协方差矩阵如何控制椭球形状</h4><p>高斯分布：$x\sim N(\mu,\sum)$，其中均值为$[\mu<em>1,\mu_2,\mu_3]$（分别代表x、y、z的值），协方差矩阵为$\sum=\left[\begin{matrix}\sigma_x^2&amp;\sigma</em>{xy}&amp;\sigma<em>{xz}&amp;\ \sigma</em>{yx}&amp;\sigma<em>y^2&amp;\sigma</em>{yz}&amp;\ \sigma<em>{zx}&amp;\sigma</em>{zy}&amp;\sigma_z^2&amp; \end{matrix}\right]$</p><p>高斯分布的仿射变化：存在A、b使得$w=Ax+b$，其中w和x是三维向量，代表xyz；w依然是高斯分布，但均值和方差变了，$w\sim N(A\mu+b,A\sum A^T)$</p><p>标准高斯分布：$x\sim N(\vec0,I)$，其中均值为$[0,0,0]$，协方差矩阵为$I=\left[\begin{matrix}\sigma^2&amp;0&amp;0&amp;\ 0&amp;\sigma^2&amp;0&amp;\ 0&amp;0&amp;\sigma^2&amp; \end{matrix}\right]$</p><p>任意高斯可以看作是标准高斯通过仿射变换得到的，即$\sum=A·I·A^T$，3维下即任意椭球可以从球仿射变换得到，所以协方差矩阵控制了椭球的形状</p><p>仿射变换是通过旋转R、平移b、缩放S得到的，故$w=Ax+b$中，$A=RS$（旋转缩放），所以$\sum=A\cdot I\cdot A^T=R\cdot S\cdot I\cdot (R\cdot S)^T=R\cdot S\cdot (S)^T\cdot (R)^T$，所以<strong>协方差矩阵可以用旋转和缩放矩阵来表示</strong></p><p>一直协方差公式，可以通过特征值分解求R和S：cholesky分解。$\sum=Q\lambda Q^T=Q\lambda^{\frac12}\lambda^{\frac12}Q^T$得到$R=Q$，$S=\lambda^{\frac12}$<br>假设$\lambda=\left[\begin{matrix}s_1&amp;&amp;&amp;\ &amp;s_2&amp;&amp;\ &amp;&amp;s_3&amp; \end{matrix}\right]=\left[\begin{matrix}\sqrt{s_1}&amp;&amp;&amp;\ &amp;\sqrt{s_2}&amp;&amp;\ &amp;&amp;\sqrt{s_3}&amp; \end{matrix}\right]\left[\begin{matrix}\sqrt{s_1}&amp;&amp;&amp;\ &amp;\sqrt{s_2}&amp;&amp;\ &amp;&amp;\sqrt{s_3}&amp; \end{matrix}\right]$，所以$\lambda =\lambda^{\frac12}\lambda^{\frac12}$成立</p><h4 id="计算协方差矩阵代码"><a href="#计算协方差矩阵代码" class="headerlink" title="计算协方差矩阵代码"></a>计算协方差矩阵代码</h4><p><img src="/2024/10/16/3DGS/image-20241016212453023.png" alt="image-20241016212453023"></p><p>输入：scale缩放(3×1维，[s1,s2,s3])，rot旋转矩阵(3*3矩阵)，mod是缩放程度，默认为1</p><h3 id="抛雪球：3D到像素"><a href="#抛雪球：3D到像素" class="headerlink" title="抛雪球：3D到像素"></a>抛雪球：3D到像素</h3><p>CG：观测变换，投影变换，视口变换，光栅化<br>可以参考B站《GAMES101-现代计算机图形学入门-闫令琪》</p><h4 id="观测变换"><a href="#观测变换" class="headerlink" title="观测变换"></a>观测变换</h4><p>世界坐标系到相机坐标系的过程，本质是仿射变换<strong>w</strong>=A<strong>x</strong>+b</p><p><img src="/2024/10/16/3DGS/image-20241016213144332.png" alt="image-20241016213144332" style="zoom:80%;"></p><h4 id="投影变换"><a href="#投影变换" class="headerlink" title="投影变换"></a>投影变换</h4><p>相机坐标系到2D空间的过程，即3D到2D</p><p><img src="/2024/10/16/3DGS/image-20241016213526511.png" alt="image-20241016213526511" style="zoom:80%;"></p><p><strong>正交投影</strong>(右图)：与深度无关，没有远小进大的概念<br><img src="/2024/10/16/3DGS/image-20241016213836626.png" alt="image-20241016213836626"><br>立方体[l,r]×[b,t]×[f,n]先平移到原点，缩放至$[-1,1]^3$的正方体<br>有缩放和平移，相当于仿射变换，即$M_{ortho}=\left[\begin{matrix}\frac2{r-l}&amp;0&amp;0&amp;0&amp;\ 0&amp;\frac2{t-b}&amp;0&amp;0&amp;\ 0&amp;0&amp;\frac2{n-f}&amp;0&amp; \ 0&amp;0&amp;0&amp;1&amp; \end{matrix}\right] \left[\begin{matrix}1&amp;0&amp;0&amp;-\frac{r+l}2&amp;\ 0&amp;1&amp;0&amp;-\frac{t+b}2&amp;\ 0&amp;0&amp;1&amp;-\frac{n+f}2&amp; \ 0&amp;0&amp;0&amp;1&amp; \end{matrix}\right]$</p><p><strong>透视投影</strong>(左图)：考虑深度信息，即远小进大<br><img src="/2024/10/16/3DGS/image-20241016214904364.png" alt="image-20241016214904364" style="zoom:80%;"></p><p>先把锥体压成立方体，再正交投影，即$M_{persp\rightarrow ortho}=\left[\begin{matrix}n&amp;0&amp;0&amp;0&amp;\ 0&amp;n&amp;0&amp;0&amp;\ 0&amp;0&amp;n+f&amp;-nf&amp; \ 0&amp;0&amp;1&amp;0&amp; \end{matrix}\right]$，属于非线性变换，即非仿射变化</p><h4 id="视口变换"><a href="#视口变换" class="headerlink" title="视口变换"></a>视口变换</h4><p>投影变换后得到一个[-1,1]范围内的正方体，再将其拉伸至原始[h,w]的图片大小</p><p><img src="/2024/10/16/3DGS/image-20241016215424640.png" alt="image-20241016215424640" style="zoom:80%;"></p><p>与z无关，将一个$[-1,1]^2$的矩阵变换至$[0,w]×[0,h]$</p><p>$M_{viewport}=\left[\begin{matrix}\frac w2&amp;0&amp;0&amp;\frac w2&amp;\ 0&amp;\frac h2&amp;0&amp;\frac h2&amp;\ 0&amp;0&amp;1&amp;0&amp; \ 0&amp;0&amp;0&amp;1&amp; \end{matrix}\right]$</p><h4 id="光栅化"><a href="#光栅化" class="headerlink" title="光栅化"></a>光栅化</h4><p>物体是连续的，而屏幕本质是离散的。通过采样让连续转离散</p><p><img src="/2024/10/16/3DGS/image-20241016215751737.png" alt="image-20241016215751737" style="zoom:80%;"><img src="/2024/10/16/3DGS/image-20241016215910606.png" alt="image-20241016215910606" style="zoom:80%;"></p><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><p>08：27</p><p><img src="/2024/10/16/3DGS/image-20241016220145497.png" alt="image-20241016220145497"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 数字人 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NeRF</title>
      <link href="/2024/10/16/NERF/"/>
      <url>/2024/10/16/NERF/</url>
      
        <content type="html"><![CDATA[<h1 id="NERF"><a href="#NERF" class="headerlink" title="NERF"></a>NERF</h1><p>学习来源：<a href="https://www.bilibili.com/video/BV1CC411V7oq/?spm_id_from=333.999.0.0&vd_source=2c97cd7eec4f38788b5479fea364bd65">【较真系列】讲人话-NeRF全解（原理+代码+公式）</a></p><h3 id="什么是NeRF"><a href="#什么是NeRF" class="headerlink" title="什么是NeRF?"></a>什么是NeRF?</h3><h5 id="广义理解定义："><a href="#广义理解定义：" class="headerlink" title="广义理解定义："></a>广义理解定义：</h5><ul><li><p>使用神经网络(MLP)来<strong>隐式的</strong>存储3D信息。</p><ul><li>显式的3D信息：有明确x，y，z的值(mesh，voxel，点云…)<ul><li>mesh：明确的xyz矩阵+边的关系</li></ul></li><li>隐式的3D信息：无明确的x&#x2F;y&#x2F;z的值，只能输出指定角度的2D图片。</li></ul></li><li><p>训练时使用给定静止场景下的若干张图片</p><img src="/2024/10/16/NERF/image-20240924091335377.png" alt="image-20240924091335377" style="zoom:80%;"></li></ul><h5 id="推论："><a href="#推论：" class="headerlink" title="推论："></a>推论：</h5><ul><li>模型不具有泛化能力</li><li>一个模型只能存储一个3D信息</li></ul><p><a href="https://arxiv.org/pdf/2003.08934">论文：</a></p><ol><li>模型输入是5D向量→粒子的空间位姿(x, y, z, theta, phi)</li><li>模型输出是4D向量→粒子对应的颜色以及密度(密度，颜色RGB)</li><li>模型是8层的MLP</li></ol><p>模型前处理：图像转5D向量</p><p>模型后处理：4D向量转2D图片</p><h3 id="真实场景及相机模型"><a href="#真实场景及相机模型" class="headerlink" title="真实场景及相机模型"></a>真实场景及相机模型</h3><p>真实场景：有多个光源+不同物体间的折射&#x2F;反射</p><p><img src="/2024/10/16/NERF/image-20240924094319157.png" alt="image-20240924094319157" style="zoom:80%;"><img src="/2024/10/16/NERF/image-20240924094415221.png" alt="image-20240924094415221" style="zoom:80%;"></p><p>相机模型：连接3d世界与2d图片</p><ul><li>世界坐标系</li><li>相机坐标系</li><li>归一化相机坐标系（物理成像平面CCD）</li><li>像素坐标系（UV坐标）</li></ul><p>补充：<a href="https://blog.csdn.net/MengYa_Dream/article/details/120233806">图像处理：4个坐标系及相关转换</a></p><h4 id="体渲染"><a href="#体渲染" class="headerlink" title="体渲染"></a>体渲染</h4><p>定义：</p><ul><li>属于渲染技术的分支，目的是解决云&#x2F;烟&#x2F;果冻等非刚性物体的渲染建模</li><li>将物质抽象成一团飘忽不定的粒子群</li><li>光线在穿过时，是光子在跟粒子发生碰撞的过程。</li></ul><p>光子与粒子发生作用的过程：</p><ul><li>吸收：光子被粒子吸收</li><li>放射：粒子本身发光</li><li>外射光：光泽在冲击后，被弹射</li><li>内射光：其他方向弹射来的粒子</li></ul><h5 id="NeRF假设："><a href="#NeRF假设：" class="headerlink" title="NeRF假设："></a>NeRF假设：</h5><ul><li>物体是一团自发光的粒子，粒子有密度和颜色</li><li>外射光和内射光抵消</li><li>多个自发光的粒子被渲染成指定角度的图片</li></ul><h3 id="NeRF的输入和输出"><a href="#NeRF的输入和输出" class="headerlink" title="NeRF的输入和输出"></a>NeRF的输入和输出</h3><p>模型的输入：将物体进行稀疏表示的<strong>单个粒子的位姿</strong></p><p>模型的输出：<strong>该粒子的密度和颜色</strong></p><img src="/2024/10/16/NERF/image-20240924095330940.png" alt="image-20240924095330940" style="zoom: 60%;"><p>问题：</p><ul><li>图片呢？</li><li>怎么得到这些粒子？</li><li>多少个粒子?这些粒子怎么批量输入？</li><li>这些粒子是怎么渲染成新的图片的？</li></ul><h3 id="粒子的采集"><a href="#粒子的采集" class="headerlink" title="粒子的采集"></a>粒子的采集</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>对于空间中的某一个自发光粒子：假设空间坐标(x,y,z)，发射的光线通过相机模型成为图片上的像素坐标(u,v)，粒子颜色即为像素颜色。</p><p>(u,v)与(x,y,z)的公式如下：</p><img src="/2024/10/16/NERF/image-20240924095751794.png" alt="image-20240924095751794" style="zoom:70%;"><p>反之，对于图片上的某一个像素(u,v)的颜色，可以看作是<strong>沿着某一条射线上的无数个发光点的“和”</strong>。</p><p>利用相机模型，反推射线，那么这个射线表示为：$r(t)&#x3D;o+td$，$o$为射线原点，$d$为方向，$t$为距离，理论上t是从0到$+∞$；用极坐标表示。</p><p><img src="/2024/10/16/NERF/image-20240924100410260.png" alt="image-20240924100410260"></p><p>如果一张照片是H×W的大小，对于整张图片共有(H,W)条射线。</p><h4 id="光线原理"><a href="#光线原理" class="headerlink" title="光线原理"></a>光线原理</h4><p>由像素点P(u, v)反推射线：</p><ul><li>像素平面→物理成像平面：$(x_n, y_n)&#x3D;(-(u-\frac{w}{2}),v-\frac{h}{2})$</li><li>物理成像平面→相机坐标系：$(x_c, y_c, z_c)&#x3D;(x_n, y_n, -f)$，其中f为焦距</li><li>归一化：$(x_c, y_c, z_c)&#x3D;(\frac{x_c}{f}, \frac{y_c}{f}, -1)$</li><li>相机坐标系→世界坐标系：$(x_w, y_w, z_w)&#x3D;c2w*(x_c, y_c, z_c)$，其中c2w指camera to world(RT旋转矩阵)</li></ul><p><img src="/2024/10/16/NERF/image-20241010204145148.png" alt="image-20241010204145148"></p><h4 id="光线代码pytorch-nerf"><a href="#光线代码pytorch-nerf" class="headerlink" title="光线代码pytorch_nerf"></a>光线代码pytorch_nerf</h4><p><img src="/2024/10/16/NERF/image-20241010205316190.png" alt="image-20241010205316190"></p><ul><li>输入：h*w，k相机内参，c2w旋转矩阵+平移矩阵</li><li>i,j：像素的表达，eg: h&#x3D;400,w&#x3D;400，i,j表示(0,0)(0,1)…</li><li>dirs：directions，归一化的相机坐标</li><li>rays_d：dirs*c2w，射线的<strong>方向</strong>，世界坐标系</li><li>rays_o：世界坐标系的原点，相机坐标原点*c2w</li><li>输出：rays_o,rays_d，射线的表达</li></ul><p>因为图像的射线有h×w个，过多，要进行筛选，所以引入batch_size，一般为1024。因为原点的表示为[x0,y0,z0]，图像上的一点为[x1,y1,z1]，所以距离为[x0-x1,y0-y1,z0-z1]，即三维[1024,3]。采样是random随机采集像素。采样一般有两种，一种是一张图片选1024个，一种是所有图片中选1024个，每个射线*各自c2w以解决不同的位姿。</p><h4 id="粒子采样原理"><a href="#粒子采样原理" class="headerlink" title="粒子采样原理"></a>粒子采样原理</h4><p>对于图片上的某一个像素(u,v)：沿着某一条射线上的无数个发光点的“和”，射线表示为：$r(t)&#x3D;o+td$，其中o为射线原点，d为方向，t为距离。理论上t从0到+∞。</p><p>但在计算中t是离散的，所以选择t的方法如下：设置near&#x3D;2,far&#x3D;6，在near和far之间均匀采样64个点，得到$t_i&#x3D;U[t_n+\frac{i-1}{N}(t_f-t_n), t_n+\frac{i}{N}(t_f-t_n)]$</p><p>在2-6中均匀采样64个点并加一些噪声，加一些扰动（效果更好，对feature的噪声更加鲁棒）<br>Robustness：承受故障和干扰的能力，一些异常的数据对整体性能的影响不大。</p><h4 id="粒子采样代码"><a href="#粒子采样代码" class="headerlink" title="粒子采样代码"></a>粒子采样代码</h4><p><img src="/2024/10/16/NERF/image-20241010210044743.png" alt="image-20241010210044743"></p><ul><li><p>near和far：size是(1024,1)，near每个数字都是2，far每个数字都是6</p></li><li><p>linespace：从0-1中采样64个</p></li><li><p>一共是1024*64个点，shape是(1024,64,3)</p></li></ul><h3 id="回答关于输入的问题"><a href="#回答关于输入的问题" class="headerlink" title="回答关于输入的问题"></a>回答关于输入的问题</h3><ol><li>图片呢?怎么得到这些粒子?<br>从图片和相机位姿计算射线，从射线上采样粒子</li><li>多少个粒子?这些粒子怎么批量输入?<br>训练时，一张图片取1024个像素，得到1024条射线，每条射线上采样64个粒子，共1024*64个粒子，粒子以batch形式输入模型</li><li>如何从2D的UV变成5D的输入？<br>以batch形式输入，[1024*64,3]，其中3代表[x,y,z]<br>输入是x,y, z, theta, phi，theta和phi在正常3D表示中分别代表了仰角和方位角，在代码里通过rays_d表示</li></ol><h3 id="输出是什么？"><a href="#输出是什么？" class="headerlink" title="输出是什么？"></a>输出是什么？</h3><p>模型的输出：该粒子的密度和颜色</p><p><img src="/2024/10/16/NERF/image-20241010210440705.png" alt="image-20241010210440705"></p><ul><li>pts：1024<em>64</em>3，即xyz</li><li>viewdirs：方向向量rays_d</li><li>network_fn：MLP多层感知器</li></ul><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>8层全连接层，半路再次输入位置坐标，后半路输出密度σ，后半路输入方向视角，最后输出颜色RGB</p><p><img src="/2024/10/16/NERF/image-20241010211442328.png" alt="image-20241010211442328"></p><h3 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h3><p><img src="/2024/10/16/NERF/image-20241010210917779.png" alt="image-20241010210917779"></p><p>如果只输入3D的xyz和3D的theta,phi，会丢失细节。所以引入位置编码，即加入sin和cos，和transformer一样</p><ul><li>对于空间坐标x，即xyz，对于每一维度都计算sin和cos，L&#x3D;10即在0-10进行计算，有20个数，三维加在一起是60维</li><li>对于视角坐标d，即rays_d，L&#x3D;4即在0-4进行计算，有8个数，三维加在一起是24维</li><li>最后加上原始的三个维度，得到xyz是63维，d是27维【初始值是代表原点？】</li></ul><p>L的值不是固定不变的，可能作者觉得粒子的坐标比方向更重要，所以如此取值。因为模型先通过坐标得到了密度的输出后，在加上direction的信息得到颜色（观测方向不应当影响密度，但会改变颜色）</p><h3 id="模型结构代码"><a href="#模型结构代码" class="headerlink" title="模型结构代码"></a>模型结构代码</h3><p><img src="/2024/10/16/NERF/image-20241010211137004.png" alt="image-20241010211137004"></p><p>整体就是全连接层FC的叠加。在第5层时再次输入位置坐标，即256+63&#x3D;319；在倒数第二层加入了direction的信息，即256+27&#x3D;283</p><h3 id="Loss的计算"><a href="#Loss的计算" class="headerlink" title="Loss的计算"></a>Loss的计算</h3><p>采用自监督：GT是图片某一像素的RGB，将该像素对应光线上的粒子颜色进行求和</p><p>粒子的颜色和：该像素颜色的预测值</p><p>粒子的颜色和（真实GT的颜色）与像素颜色（预测的颜色）做MSE：$L&#x3D;\sum_{r∈R}||\hat{C}(r)-C(r)||_2^2$，其中r是射线，R是每个batch的射线(1024条)</p><h3 id="体渲染-1"><a href="#体渲染-1" class="headerlink" title="体渲染"></a>体渲染</h3><p>如何将光线上粒子颜色进行求和？</p><p>T(s)：在s点之前，光线没有被阻碍的概率；如果光线被阻碍，T(s)&#x3D;0，则无后续颜色</p><p>σ(s)：在s点处，光线碰击粒子(光线被粒子阻碍)的概率密度</p><p>C(s)：在s点处，粒子光出的颜色</p><p>σ(s)和C(s)是模型的输出，各点的颜色和概率密度已知，先求T(s)</p><p>$\hat{C(r)}&#x3D;\int_0^{+\infty}T(s)\sigma(s)C(s)ds$</p><p>$T(s)&#x3D;e^{-\int_0^s\sigma(t)dt}$</p><p><img src="/2024/10/16/NERF/image-20241016135927932.png" alt="image-20241016135927932" style="zoom: 80%;"><img src="/2024/10/16/NERF/image-20241016140605711.png" alt="image-20241016140605711" style="zoom:80%;"></p><h4 id="T-s-的推导"><a href="#T-s-的推导" class="headerlink" title="T(s)的推导"></a>T(s)的推导</h4><p>σ表示密度，密度越大，不被阻拦的概率越小，即1-σ(s)ds</p><p>T(0)在原点不被阻障的概率，T(0)&#x3D;1，lnT(0)&#x3D;0</p><p>$T(s+ds)&#x3D;T(s)[1-\sigma(s)ds]&#x3D;T(s)-T(s)\sigma(s)ds$</p><p>$T(s+ds)-T(s)&#x3D;-T(s)\sigma(s)ds$</p><p>$dT(s)&#x3D;-T(s)\sigma(s)ds$</p><p>$ \frac{dT(s)}{T(s)}&#x3D;-\sigma(s)ds$</p><p>$\int_0^t-\sigma(s)ds&#x3D;\int_0^t\frac{dT(s)}{T(s)}&#x3D;\int_0^t\frac{1}{T(s)}dT(s)&#x3D;\ln T(s)\vert_0^t&#x3D;\ln T(t)-\ln T(0)&#x3D;\ln T(t)$</p><p>$T(t)&#x3D;e^{-\int_0^s\sigma(t)dt}$</p><h4 id="离散积分"><a href="#离散积分" class="headerlink" title="离散积分"></a>离散积分</h4><p>计算机只能处理离散化数据</p><p>将光线[0,s]划分为N个等间距区间[$T_n$→$T_{n+1}$]，其中n&#x3D;0,1,2,…,N；间隔长度为$\delta_n$，假设区间内密度$\sigma_n$和颜色$C_n$固定</p><p>$\hat{C(r)}&#x3D;\sum_{i&#x3D;1}^NT_i(1-e^{-\sigma_i\delta_i})C_i$，where $T_i&#x3D;e^{-\sum_{j&#x3D;1}^{i-1}\sigma_j\delta_j}$</p><h5 id="离散积分推导"><a href="#离散积分推导" class="headerlink" title="离散积分推导"></a>离散积分推导</h5><p>每个光区贡献光强进行累加$\hat{C}&#x3D;\sum_{n&#x3D;0}^NI(T_n\rightarrow T_{n+1})$，其中s是沿光流方向的光线的长度，I(s)是距离s处的光强度</p><p>$$<br>\begin{align*}<br>I(T_n\rightarrow T_{n+1}) &amp;&#x3D; \int_{t_n}^{t_{n+1}}T(t)\sigma(n)C(n)dt \<br>&amp;&#x3D; \sigma(n)C(n)\int_{t_n}^{t_{n+1}}T(t)dt \<br>&amp;&#x3D; \sigma(n)C(n)\int_{t_n}^{t_{n+1}}e^{-\int_0^t\sigma(s)ds}dt\<br>&amp;&#x3D; \sigma(n)C(n)\int_{t_n}^{t_{n+1}}e^{-(\int_0^{t_n}\sigma(s)ds+\int_{t_n}^t\sigma(s)ds)}dt\<br>&amp;&#x3D; \sigma(n)C(n)\int_{t_n}^{t_{n+1}}e^{-\int_0^{t_n}\sigma(s)ds}e^{-\int_{t_n}^t\sigma(s)ds}dt\<br>&amp;&#x3D; \sigma(n)C(n)T(0\rightarrow t_n)\int_{t_n}^{t_{n+1}}e^{-\int_{t_n}^t\sigma(s)ds}dt\<br>&amp;&#x3D; \sigma(n)C(n)T(0\rightarrow t_n)\int_{t_n}^{t_{n+1}}e^{-\int_{t_n}^t\sigma_nds}dt\<br>&amp;&#x3D; \sigma(n)C(n)T(0\rightarrow t_n)\int_{t_n}^{t_{n+1}}e^{-\sigma_n(t-t_n)}dt【注：\sigma(n)是常数，做积分原函数是x，故得到t-t_n】\<br>&amp;&#x3D; \sigma(n)C(n)T(0\rightarrow t_n)[-\frac1{\sigma_n}e^{-\sigma_n(t-t_n)}\vert_{t_n}^{t_{n+1}}]\<br>&amp;&#x3D; \sigma(n)C(n)T(0\rightarrow t_n)(-\frac1{\sigma_n}(e^{-\sigma_n\delta_n}-1))【注：e^{-\sigma_n(t-t_n)}\vert_{t_n}^{t_{n+1}} &#x3D; e^{-\sigma_n(t_{n+1}-t_n)}-e^{-\sigma_n(t_n-t_n)} &#x3D; e^{-\sigma_n\delta_n}-1】\<br>&amp;&#x3D; C(n)T(0\rightarrow t_n)(-e^{-\sigma_n\delta_n}+1)【注：约去\sigma(n)】\<br>&amp;&#x3D; C(n)e^{-\sum_{i&#x3D;0}^{n-1}\sigma_i\delta_i}(-e^{-\sigma_n\delta_n}+1)【注：T(0\rightarrow t_n)&#x3D;e^{-\int_0^{t_n}\sigma(s)ds}&#x3D;e^{-\sum_{i&#x3D;0}^{n-1}\sigma_i\delta_i}】\<br>\end{align*}<br>$$<br>$\hat{C}&#x3D;\sum_{n&#x3D;0}^NI(T_n\rightarrow T_{n+1})&#x3D;\sum_{n&#x3D;0}^NC_ne^{-\sum_{i&#x3D;0}^{n-1}\sigma_i\delta_i}(-e^{1-\sigma_n\delta_n})$</p><p>设$\alpha_n&#x3D;1-e^{-\sigma_n\delta_n}$，即$e^{-\sigma_n\delta_n}&#x3D;1-a_n$可以看作第n个点的不透明度<br>$$<br>\begin{align*}<br>e^{-\sum_{i&#x3D;0}^{n-1}\sigma_i\delta_i} &amp;&#x3D; e^{-(\sigma_0\delta_0+\sigma_1\delta_1+…+\sigma_{n-1}\delta_{n-1})}\<br>&amp;&#x3D; e^{-\sigma_0\delta_0}e^{-\sigma_1\delta_1}…e^{-\sigma_{n-1}\delta_{n-1}}\<br>&amp;&#x3D; (1-a_0)(1-a_1)…(1-a_{n-1})\<br>故\hat{C}&amp;&#x3D;\sum_{n&#x3D;0}^NC_na_n(1-a_0)(1-a_1)…(1-a_{n-1})\<br>&amp;&#x3D;C_0a_0+C_1a_1(1-a_0)+C_2a_2(1-a_0)(1-a_1)+…+C_na_n(1-a_0)(1-a_1)…(1-a_{n-1})<br>\end{align*}<br>$$</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>delta_n：粒子取样的间隔，相同的数，大致都是0.06</p><p><img src="/2024/10/16/NERF/image-20241016155640007.png" alt="image-20241016155640007"></p><p>一个射线对应一个像素，最后得到1024*3，3指rgb</p><h3 id="回答关于输出的问题"><a href="#回答关于输出的问题" class="headerlink" title="回答关于输出的问题"></a>回答关于输出的问题</h3><p>这些粒子是怎么渲染成新的图片的？<br>分别计算图片中每一个像素的颜色，计算该像素对应的光线和粒子，将这些粒子通过公式累加，得到该像素最终颜色。</p><h3 id="二次采样"><a href="#二次采样" class="headerlink" title="二次采样"></a>二次采样</h3><p>目前有效区域和无效区域(空白区域和遮挡区域)都是均匀采样</p><p>我们希望：有效区域多采样，无效区域少采样或不采样</p><p>解决方法：可以根据概率密度进行再次采样</p><p><img src="/2024/10/16/NERF/image-20241016160028491.png" alt="image-20241016160028491"></p><h4 id="最终模型结构"><a href="#最终模型结构" class="headerlink" title="最终模型结构"></a>最终模型结构</h4><p>两个8层的MLP串联得到最终模型，第一个MLP为粗模型（均匀采样64个点，得到点的概率密度函数），第二个MLP叫细模型（根据一个模型的概率密度函数，二次采样更有价值点，再进行粒子的求和，得到最终的像素颜色值）</p><p>粗模型和细模型结构相同，最后输出为模型2的输出</p><h4 id="逆变换采样"><a href="#逆变换采样" class="headerlink" title="逆变换采样"></a>逆变换采样</h4><p>细模型根据密度进行二次采样的方法：</p><ul><li>根据粗模型的结果，进行逆变换采样。</li><li>对于每条光线，重新采样128个粒子，与之前的64个粒子加在一起，即每条光线采样192个粒子。</li><li>对于每条射线上的粒子颜色前的权重，即$\alpha_n(1-\alpha_0)(1-\alpha_1)…(1-\alpha_{n-1})$做softmax，即$\hat{w_j}&#x3D;\frac{w_i}{\sum_{j&#x3D;1}^{N_c}w_i}$，此时，新的权重和为1，可看作PDF(概率密度函数)</li><li>生成它的cdf(累积分布函数，概率密度函数的积分)</li><li>invert cdf(反函数)</li><li>用均匀分布drand480生成一个随机数：invert(drand48)&#x3D;r，得到的r就是符合pdf分布的随机数</li></ul><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><p><img src="/2024/10/16/NERF/image-20241016161034828.png" alt="image-20241016161034828"></p><p>最后输出(192,3)维度的颜色数据</p><h3 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h3><p>输入：400×400条射线上分别采样64个点</p><p>输出：[400×400×192,4]，其中[h×w×192,4]中4指rgb和σ；进行体渲染</p><p><img src="/2024/10/16/NERF/image-20241016161301952.png" alt="image-20241016161301952"></p><h3 id="Loss是怎样计算的"><a href="#Loss是怎样计算的" class="headerlink" title="Loss是怎样计算的?"></a>Loss是怎样计算的?</h3><p><img src="https://upload-images.jianshu.io/upload_images/12824314-33db12476e16fd6a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1142/format/webp" alt="img"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>前处理：</p><ul><li>将图片中的每个像素，通过相机模型找到对应的射线</li><li>在每条射线上进行采样，得到64个粒子</li><li>对batch_size*64个粒子进行位置编码</li><li>位置坐标为63D和方向向量为27D</li></ul><p>模型1：</p><ul><li>8层MLP</li><li>输入为(batch_size,64,63)和(batch_size,64,27)</li><li>输出为(batch_size,64,4)</li></ul><p>后处理1：</p><ul><li>计算模型1的输出，对射线进行二次采样</li><li>每条射线上共采样192个粒子</li></ul><p>模型2：</p><ul><li>8层MLP</li><li>输入为(batch_size,192,63)和(batch_size,192,27)</li><li>输出为(batch_size,192,4)</li></ul><p>后处理2：将模型2输出通过体渲染，转换为像素。</p><p>核心内容：体渲染、位置编码、层级采样</p><p>缺点：很慢，训练&#x2F;推理都慢；只能表达静态场景；对光照处理的一般；没有泛化能力。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 数字人 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达2022机器学习</title>
      <link href="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="课程来源"><a href="#课程来源" class="headerlink" title="课程来源"></a>课程来源</h2><p><a href="https://www.bilibili.com/video/BV1Zt4y1H78P/?share_source=copy_web&amp;vd_source=de6d7d10ceabb39ea60e61fa8c108937">吴恩达2022机器学习专项课程(一）监督学习 Supervised Learning</a></p><p><a href="https://www.bilibili.com/video/BV1nt4y1h7jc/?share_source=copy_web&vd_source=de6d7d10ceabb39ea60e61fa8c108937">吴恩达2022机器学习专项课程(二）：高级学习算法 Advanced Learning Algorithms</a></p><p><a href="https://www.bilibili.com/video/BV1ja411S7Wq/?share_source=copy_web&vd_source=de6d7d10ceabb39ea60e61fa8c108937">吴恩达2022机器学习专项课程(三）：无监督学习&#x2F;推荐系统&#x2F;强化学习 Unsupervised Learning&#x2F;Recommenders&#x2F;Reinforcement</a></p><h2 id="分类算法Classification"><a href="#分类算法Classification" class="headerlink" title="分类算法Classification"></a>分类算法Classification</h2><p>二分类问题(binary classification)：结果只有两种可能的类(classes)，或两种可能的类别(categories)</p><p>术语：正样本(positive class)：true&#x2F;1；负样本(negative class)：false&#x2F;0</p><p>线性回归会因为添加训练样本而改变预测结论，如下图所示：<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804212737004.png" alt="image-20240804212737004" style="zoom:50%;"></p><h3 id="逻辑回归算法Logistic-Regression"><a href="#逻辑回归算法Logistic-Regression" class="headerlink" title="逻辑回归算法Logistic Regression"></a>逻辑回归算法Logistic Regression</h3><p>逻辑回归方程：$f_\vec{w},_b(\vec{x})&#x3D;g(\vec{w}\cdot\vec{x}+b)&#x3D;\frac{1}{1+e^{-(\vec{w}\cdot\vec{x}+b)}}$</p><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804213348751.png" alt="image-20240804213348751" style="zoom:50%;"><p>可以把输出看作是在给定输入x的情况下，类别或标签y等于1的概率。</p><p>$f_\vec{w},_b(\vec{x})&#x3D;P(y&#x3D;1|\vec{x},\vec{w},b)$：表明在给定输入特征w和b（参数w和b影响计算）的前提下，y&#x3D;1的概率是多少（条件概率）</p><p>设置一个阈值(threshold) ，超过这个阈值则预测y&#x3D;1，通常阈值被设置为0.5。</p><p>通过阈值预测结果的原理如下图蓝框内容：<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804214826761.png" alt="image-20240804214826761" style="zoom:50%;"></p><h3 id="决策边界Decision-Boundary"><a href="#决策边界Decision-Boundary" class="headerlink" title="决策边界Decision Boundary"></a>决策边界Decision Boundary</h3><p>线性和非线性决策边界示例如下：<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804215353490.png" alt="image-20240804215353490" style="zoom:50%;"><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804215430301.png" alt="image-20240804215430301" style="zoom:50%;"></p><p>通过多项式特征，可以得到非常复杂的决策边界。换包话说，逻辑回归可以学会拟合相当复杂的数据。</p><p>如果不使用高阶多项式，那么逻辑回归的决策边界永远是线性的。</p><h3 id="代价函数Cost-Function"><a href="#代价函数Cost-Function" class="headerlink" title="代价函数Cost Function"></a>代价函数Cost Function</h3><p>逻辑回归函数的代价函数是非凸的(non-convex)，这意味着如果想用梯度下降法，因为有很多局部极小值，所以很容易卡在这些地方。<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804220308650.png" alt="image-20240804220308650" style="zoom:50%;"><br>所以我们需要让代价函数再次凸化，保证梯度下降可以收敛道全局最小值。如上图$J(\vec{w},b)$（1&#x2F;2被挪到了累加公式里）。</p><p>损失函数衡量的是在一个训练样本中的表现，把所有的训练样本的损失加起来得到的代价函数，才能衡量模型在整个训练集上的表现。</p><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804221342091.png" alt="image-20240804221342091" style="zoom:50%;"><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804221614563.png" alt="image-20240804221614563" style="zoom:50%;"><p>为了便于写代码，可以将损失函数L简化，简化后的损失函数(loss function)和代价函数(cost function)如下所示：<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804222203792.png" alt="image-20240804222203792" style="zoom:50%;"></p><p><a href="https://blog.csdn.net/qq_41775769/article/details/113514294">一文彻底读懂【极大似然估计】-CSDN博客</a></p><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>&#x3D;&#x3D;导数结果不懂，前面整理完后回顾&#x3D;&#x3D;</p><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804223110637.png" alt="image-20240804223110637" style="zoom:50%;"><p><a href="https://www.cnblogs.com/zhongmiaozhimen/p/6155093.html">第三周：逻辑回归代价函数求导过程 - 玄天妙地 - 博客园 (cnblogs.com)</a></p><h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h3><p>欠拟合underfit、高偏差high bias、泛化generalization、过拟合overfit、高方差high variance<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804224609969.png" alt="image-20240804224609969" style="zoom:50%;"></p><p>解决过拟合的方法：①增加训练样本②使用更少的特征（特征选择feature selection）③正则化regularization</p><h3 id="正则化Regularization"><a href="#正则化Regularization" class="headerlink" title="正则化Regularization"></a>正则化Regularization</h3><p>正则化是尽可能地让算法缩小参数的值，而不是一定要求参数为0。</p><p>当模型参数很多时，我们不清楚哪些参数是最重要的，就会对所有参数进行惩罚，即把所有参数都缩小点。<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804225912759.png" alt="image-20240804225912759" style="zoom:50%;"><br>上式中$$\lambda$$表示正则化参数；累加函数前都除以2m，是为了用同样的方式缩放，这样选择正则化参数$$\lambda$$会更容易，其中m是数据集的大小，这样及时训练集的规模变大，正则化参数$$\lambda$$可能还可以使用。参数b在实践中产生的影响很小，所以可以更多的去正则化参数w，而不是b。</p><p>最小化第一项可以让(预测值-真实值)^2^尽可能的小，使算法能更好地拟合数据；最小化第一项可以让参数w尽可能的小，减小过拟合的风险。<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804231054281.png" alt="image-20240804231054281" style="zoom:50%;"></p><p>正则化参数$$\lambda$$值体现了相对重要性或相对权衡，即如何取舍上述两个目标。$$\lambda&#x3D;0$$则模型过拟合，$$\lambda&#x3D;\infty$$则模型缺乏对数据的拟合；所以理想中的$$\lambda$$值是介于两者之间的，能恰当的平衡第一项和第二项。</p><h4 id="线性回归的正则化"><a href="#线性回归的正则化" class="headerlink" title="线性回归的正则化"></a>线性回归的正则化</h4><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804231701124.png" alt="image-20240804231701124" style="zoom:50%;"><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804232756152.png" alt="image-20240804232756152" style="zoom:50%;"><p>$$w_j(1-\alpha\frac{\lambda}{m})$$让每次循环w都减少一点点，从而达到正则化的效果。</p><p>代价函数具体的导数推理如下：<br><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804233214830.png" alt="image-20240804233214830" style="zoom:50%;"></p><h4 id="逻辑回归的正则化"><a href="#逻辑回归的正则化" class="headerlink" title="逻辑回归的正则化"></a>逻辑回归的正则化</h4><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240804233516282.png" alt="image-20240804233516282" style="zoom:50%;"><h2 id="神经网络Neural-Networks"><a href="#神经网络Neural-Networks" class="headerlink" title="神经网络Neural Networks"></a>神经网络Neural Networks</h2><p>应用领域：语音识别speech、计算机视觉images、自然语言处理text(NLP)、……</p><p>激活项(activation)指的是一个神经元向下游的其他神经元发送高输出的数量。</p><p>layer：一层是一组神经元，它让我们输入相同或相似的特征，然后一起输出几个数字。一层可以有一个或多个神经元。</p><p>输出层output layer：最后一个神经元的输出就是整个神经网络预测的输出概率。【逻辑回归】</p><p>输入层input layer、隐藏层hidden layer（作用：自动提取更加好的特征，送入逻辑回归中进行预测）</p><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240805235712084.png" alt="image-20240805235712084" style="zoom:50%;">有多层的神经网络被称为多层感知器(multilayer perception)<h3 id="神经网络工作原理"><a href="#神经网络工作原理" class="headerlink" title="神经网络工作原理"></a>神经网络工作原理</h3><p>函数g是激活函数，本图举例的是S型函数。</p><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806000738368.png" alt="image-20240806000738368" style="zoom:50%;"><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806000932626.png" alt="image-20240806000932626" style="zoom:50%;"><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806001157563.png" alt="image-20240806001157563" style="zoom:50%;"><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806155510812.png" alt="image-20240806155510812" style="zoom:50%;"><p>前向传播forward propagation：为传播神经元的激活值，需要从左到右前进的方向进行计算。</p><h3 id="Tensorflow实践"><a href="#Tensorflow实践" class="headerlink" title="Tensorflow实践"></a>Tensorflow实践</h3><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806160408397.png" alt="image-20240806160408397" style="zoom:50%;"><p>密集层（Dense Layer）是深度学习中常用的一种神经网络层，也被称为全连接层（Fully Connected Layer）或线性层（Linear Layer）。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[<span class="number">200.0</span>, <span class="number">17.0</span>]])</span><br><span class="line">layer_1 = Dense(units=<span class="number">3</span>, activation=‘sigmoid’)</span><br><span class="line">a1 = layer_1(x)//a1是一个<span class="number">1</span>*3matrix </span><br><span class="line">// a1: tf.Tensor([[<span class="number">0.2</span> <span class="number">0.7</span> <span class="number">0.3</span>]], shape=(<span class="number">1</span>, <span class="number">3</span>), dtype=float32) 其中Tensor是TF创建的一种数据类型，可以有效地存储和执行矩阵计算，张量比矩阵更具有一般性。</span><br><span class="line">// a1.numpy()=array([[<span class="number">1.4661001</span>, <span class="number">1.125196</span> , <span class="number">3.2159438</span>]], dtype=float32)</span><br><span class="line">layer_2 = Dense(units=<span class="number">1</span>, activation=‘sigmoid’)</span><br><span class="line">a2 = layer_2(a1)// tf.Tensor([[<span class="number">0.8</span>]], shape=(<span class="number">1</span>, <span class="number">1</span>), dtype=float32)</span><br><span class="line">// a2.numpy()=array([[<span class="number">0.8</span>]], dtype=float32)</span><br><span class="line"><span class="keyword">if</span> a2 &gt;= <span class="number">0.5</span>:</span><br><span class="line">yhat = <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">yhat = <span class="number">0</span></span><br><span class="line">------------------------------</span><br><span class="line">layer_1 = Dense(units=<span class="number">3</span>, activation=<span class="string">&quot;sigmoid&quot;</span>)</span><br><span class="line">layer_2 = Dense(units=<span class="number">1</span>, activation=<span class="string">&quot;sigmoid&quot;</span>)</span><br><span class="line">model = Sequential([layer_1, layer_2])// 顺序框架</span><br><span class="line">x = np.array([[<span class="number">200.0</span>, <span class="number">17.0</span>],</span><br><span class="line">              [<span class="number">120.0</span>, <span class="number">5.0</span>],</span><br><span class="line">              [<span class="number">425.0</span>, <span class="number">20.0</span>],</span><br><span class="line">              [<span class="number">212.0</span>, <span class="number">18.0</span>]])</span><br><span class="line">y = np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">model.<span class="built_in">compile</span>(...)// wait more...</span><br><span class="line">model.fit(x,y)</span><br><span class="line">model.predict(x_new)</span><br></pre></td></tr></table></figure><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806160621956.png" alt="image-20240806160621956" style="zoom:50%;"><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// 手写图形分类</span><br><span class="line">x = np.array([[<span class="number">0.0</span>,..<span class="number">.245</span>,..<span class="number">.240</span>..<span class="number">.0</span>]])</span><br><span class="line">layer_1 = Dense(units=<span class="number">25</span>, activation=‘sigmoid’)</span><br><span class="line">a1 = layer_1(x)</span><br><span class="line">layer_2 = Dense(units=<span class="number">15</span>, activation=‘sigmoid’)</span><br><span class="line">a2 = layer_2(a1)</span><br><span class="line">layer_3 = Dense(units=<span class="number">1</span>, activation=‘sigmoid’)</span><br><span class="line">a3 = layer_3(a2)</span><br><span class="line"><span class="keyword">if</span> a3 &gt;= <span class="number">0.5</span>:</span><br><span class="line">yhat = <span class="number">1</span>// 独热变量</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">yhat = <span class="number">0</span></span><br><span class="line">------------------------------</span><br><span class="line">model = Sequential([</span><br><span class="line">    Dense(units=<span class="number">25</span>, activation=<span class="string">&quot;sigmoid&quot;</span>),</span><br><span class="line">    Dense(units=<span class="number">15</span>, activation=<span class="string">&quot;sigmoid&quot;</span>),</span><br><span class="line">    Dense(units=<span class="number">1</span>, activation=<span class="string">&quot;sigmoid&quot;</span>)])</span><br><span class="line">model.<span class="built_in">compile</span>(...)</span><br><span class="line">x = np.array([[<span class="number">0.</span>.., <span class="number">245</span>, ..., <span class="number">17</span>],</span><br><span class="line">  [<span class="number">0.</span>.., <span class="number">200</span>, ..., <span class="number">184</span>]])</span><br><span class="line">y = np.array([<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">model.fit(x,y)</span><br><span class="line">model.predict(x_new)</span><br></pre></td></tr></table></figure><p>独热编码(one-hot)：也称独热变量，是分类变量作为二进制向量的表示。<br>eg：性别特征[“女”,”男”]按照N位状态寄存器来对N个状态进行编码的原理（这里只有两个特征，所以N&#x3D;2），处理后应该是：女&#x3D;&gt; 10、男&#x3D;&gt;01；同理，祖国特征[“中国”，”美国，”法国”]（这里N&#x3D;3）：中国 &#x3D;&gt; 100、美国 &#x3D;&gt; 010、法国 &#x3D;&gt; 001。<br>所以，当一个样本为[“女”,”中国”]的时候，完整的特征数字化的结果为：[1，0，1，0，0]。而我们使用one-hot编码将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散型特征使用one-hot编码，会让特征之间的距离计算更加合理。</p><h4 id="numpy数据表示"><a href="#numpy数据表示" class="headerlink" title="numpy数据表示"></a>numpy数据表示</h4><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806162303550.png" alt="image-20240806162303550" style="zoom:50%;"><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806162450369.png" alt="image-20240806162450369" style="zoom:50%;"><p>二维矩阵常用于Tensorflow，一维向量常用于线性回归、逻辑回归。</p><h3 id="单层上的向前传播forward-prop"><a href="#单层上的向前传播forward-prop" class="headerlink" title="单层上的向前传播forward prop"></a>单层上的向前传播forward prop</h3><ol><li>设置每一个神经元的w，b值。从而得到z值。</li><li>通过sigmoid function（也就是g(z)）来得到预测值a。</li><li>将第一层的每个神经元的预测结果组合为向量a1。</li><li>使用a1作为layer2的input，再来预测a2的值（最终结果）.</li></ol><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806164444177.png" alt="QQ截图20240806164444" style="zoom:50%;"><h3 id="前向传播的一般实现"><a href="#前向传播的一般实现" class="headerlink" title="前向传播的一般实现"></a>前向传播的一般实现</h3><p>简化上面的过程，从而实现更通用的forward prop，而不是对每个神经元写代码</p><img src="/2024/08/04/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20240806170400177.png" alt="image-20240806170400177" style="zoom:50%;">]]></content>
      
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
